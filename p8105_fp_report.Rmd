---
title: "P8105 Final Project: Determinants of Global Violence"
author: "My An Huynh, Jeffrey Lin, Soo Min You, Hyun Kim, Malika Top"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(countrycode)
```

## Motivation

## Initial Questions

# Data: Source, Scraping Method & Cleaning

## Source

Since there are many determinants and indicators of violence, we chose the 
indicators and outcomes that we thought were most interesting and relevant in 
exploring violence from the following sources:

* International Monetary Fund (IMF)
  - Unemployment Rate
* United Nations Development Program (UNDP): 
  - Human Development Index
* United Nations Office of Drugs and Crime (UNODC)
  - Corruption and Economic Crime
  - Criminal Justice Personnel
  - Human Trafficking
  - Intentional Homicide
  - Violent and Sexual Crimes
* World Bank
  - Gross Domestic Product (GDP)
  - Inflation Rate (Measured by Consumer Price Index)
* World Health Organization (WHO)
  - Alcohol Consumption

Intentional homicide, and violent and sexual crimes were chosen as the outcome 
variable to quantify violence. 

* Intentional homicide:
  - counting unit: individual victim of homicide
  - classification:
    - situational context: organized crime, interpersonal (excluding familial/intimate),
    socio-political
    - relationship to perpetrator: intimate partner, family member, friend, colleague, etc.
    - mechanism: firearm, weapon, physical force

* Violent and sexual crimes:
  - counting unit: number of individual offences per 100,000 population
  - classification of offenses:
    - rape
    - serious assault
    - kidnapping
    - sexual violence
  - NOTE: some countries used other counting unit (a series of offenses to form a case, or multiple cases to form an investigation)


## Scraping Method

The datasets were downloaded from the official websites of the sources above. 
The names of the files were also changed accordingly for clarity and to avoid 
confusion. For example, the alcohol consumption data file was renamed from 
"data.csv" to "alcohol_consumption.csv".

## Cleaning

### Economic Determinants
```{r tidy_econ_determinants}

gdp_df = 
  read_excel(
    path = "data/worldbank/gdp.xls",
    sheet = "Data",
    skip = 3,
    na = ""
  ) |>
  select(country = 2, "2015":"2023")

inflation_df = 
  read_excel(
    path = "data/worldbank/inflation_rate.xls",
    sheet = "Data",
    skip = 3,
    na = ""
  ) |>
  select(country = 2, "2015":"2023") 

unemployment_df =
  read_excel(
    path = "data/imf/unemployment_rate.xls",
    range = "A1:AY116",
    na = "no data"
  ) |>
  select(country = 1, "2015":"2023") 

human_develop_df =
  read_csv(
    file = "data/undp/human_development_index.csv",
    na = "") |>
  head(-11) |>
  rename_with(gsub, pattern = "^hdi_", replacement = "") |>
  select(country = 1, "2015":"2022")
```

### Function to pivot data

```{r pivot_data}
pivot_df = function(data, name, value) {
  
  data |>
    pivot_longer(
      cols = -country,
      names_to = "year",
      values_to = paste(name)
    ) |>
    janitor::clean_names() |>
    mutate(year = as.numeric(year),
          country = countrycode(country, origin = value,
                               destination = "country.name",
                               nomatch = NA)) |>
    drop_na()
}

gdp_df = pivot_df(gdp_df, "gdp", "iso3c")
inflation_df = pivot_df(inflation_df, "inflation", "iso3c")
human_develop_index_df = pivot_df(human_develop_df, "hdi", "iso3c")
unemployment_df = pivot_df(unemployment_df, "unemployment_rate", "country.name")
```

### Social Determinants
```{r tidy_social_determinants}
crime_rate_df = 
  read_excel(
    path = "data/unodc/corruption_economic_crime.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(unit_of_measurement == "Rate per 100,000 population") |>
  mutate(year = as.numeric(year),
         iso3_code = str_replace_all(iso3_code, "^GBR.*", "GBR"),
         iso3_code = str_replace_all(iso3_code, "^IRQ.*", "IRQ"),
         country = countrycode(iso3_code, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA)) |>
  group_by(country, region, year) |>
  summarize(avg_crime_rate = mean(value))

justice_personnel_df =
  read_excel(
    path = "data/unodc/criminal_justice_personnel.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(indicator == "Criminal Justice Personnel",
         unit_of_measurement == "Rate per 100,000 population",
         sex == "Total") |>
  mutate(year = as.numeric(year),
         iso3_code = str_replace_all(iso3_code, "^GBR.*", "GBR"),
         iso3_code = str_replace_all(iso3_code, "^IRQ.*", "IRQ"),
         country = countrycode(iso3_code, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA)) |>
  group_by(country, region, year) |>
  summarize(avg_personnel_rate = mean(value))

trafficking_df =
  read_excel(
    path = "data/unodc/human_trafficking.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(category == "Total",
         sex == "Total",
         age == "Total",
         txt_value != "<5") |>
  mutate(txt_value = str_replace_all(txt_value, ",", ""),
         txt_value = as.numeric(txt_value), 
         year = as.numeric(year), 
         country = countrycode(iso3_code, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA)) |>
  group_by(country, region, year) |>
  summarize(total_trafficking = sum(txt_value))

alcohol_consumption_df =
  read_csv(
    file = "data/who/alcohol_consumption.csv", 
    na = ""
  ) |>
  janitor::clean_names() |>
  filter(dim1 == "Both sexes") |>
  select(country = spatial_dim_value_code, year = period, 
         alcohol_consumption = fact_value_numeric) |>
  mutate(year = as.numeric(year),
         country = countrycode(country, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA))
```

### Outcomes of Violence
```{r tidy_violence_outcomes}
homicide_rate_df = 
    readxl::read_excel(
    path = "data/unodc/intentional_homicide.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(indicator == "Victims of intentional homicide",
         unit_of_measurement == "Rate per 100,000 population",
         dimension == "Total",
         sex == "Total",
         age == "Total") |>
  mutate(year = as.numeric(year),
         iso3_code = str_replace_all(iso3_code, "^GBR.*", "GBR"),
         iso3_code = str_replace_all(iso3_code, "^IRQ.*", "IRQ"),
         country = countrycode(iso3_code, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA)) |>
  select(country, region, year, homicide_rate = value)

violence_rate_df = 
    readxl::read_excel(
    path = "data/unodc/violent_sexual_crime.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(indicator == "Violent offences",
         unit_of_measurement == "Rate per 100,000 population") |>
  pivot_wider(
    names_from = indicator,
    values_from = value
  ) |>
  rename(violence_rate = "Violent offences") |>
  mutate(year = as.numeric(year),
         iso3_code = str_replace_all(iso3_code, "^GBR.*", "GBR"),
         iso3_code = str_replace_all(iso3_code, "^IRQ.*", "IRQ"),
         country = countrycode(iso3_code, origin = "iso3c",
                               destination = "country.name",
                               nomatch = NA)) |>
  group_by(country, year) |>
  summarize(avg_violence_rate = mean(violence_rate)) 
```

For the economic determinants, all the datasets had years organized as different
columns, where each column represented values for that specific year. Therefore, 
pivot_longer() was applied to pivot years and their respective values into two 
columns. 

For rates of all social determinants, we filtered and chose the data to be 
rates per 100,000 people since it allows standardization for comparability by
adjusting for differences in population size. 

The countrycode() function from the countrycode package was also implemented in 
order to standardize the country names of each dataset since some of the 
country names were represented inconsistently across datasets. For example, 
South Korea was represented as "Korea (Republic of)" and "Korea, Rep."

### Merge Datasets
```{r merge_datasets}
merged_violence_df =
  left_join(homicide_rate_df, violence_rate_df) |>
  left_join(gdp_df) |>
  left_join(inflation_df) |>
  left_join(unemployment_df) |>
  left_join(human_development_df) |>
  left_join(crime_rate_df) |>
  left_join(justice_personnel_df) |>
  left_join(trafficking_df) |>
  left_join(alcohol_consumption_df) |>
  mutate(country = as.factor(country),
         region = as.factor(region)) |>
  filter(between(year, 2015, 2023)) |>
  drop_na(country, region)

str(merged_violence_df)
```

The final merged dataset includes `r nrow(merged_violence_df)` rows and 
`r ncol(merged_violence_df)` columns, including country, region, year, homicide 
rate, average violence offence rate, gdp, inflation rate, unemployment rate, 
average crime rate, average (criminal justice) personnel rate, total drug 
seized (2018 - 2022), total arm seized, total trafficking and alcohol 
consumption as variables. There is a total of 
`r length(unique(pull(merged_violence_df, country)))` distinct countries. 

After merging the datasets, country and region were converted to categorical 
variables. Rows with NA values for country and region were dropped, and the 
dataset was filtered for the years between 2015 and 2023. 

# EDA

## Visualization

```{r}
homicide_visual_df = 
    readxl::read_excel(
    path = "data/unodc/intentional_homicide.xlsx",
    skip = 2
  ) |>
  janitor::clean_names() |>
  filter(indicator == "Victims of intentional homicide",
         unit_of_measurement == "Rate per 100,000 population",
         category != "Total",
         sex != "Total",
         between(year, 2015, 2023)) |>
  select(country, region, category, sex, year, homicide_rate = value)
```

```{r}
homicide_visual_df |>
  group_by(region, year) |>
  summarize(avg_homicide_rate = mean(homicide_rate)) |>
  ggplot(aes(y = avg_homicide_rate, x = as.factor(year), fill = region)) +
  geom_col(position = "dodge", bin = 3.0) + 
  labs(x = "Year",
       y = "Average Homicide Rate",
       Title = "Average Homicide Rate Across Region")
```
```{r}
homicide_visual_df |>
  group_by(region, sex, year) |>
  summarize(avg_homicide_rate = mean(homicide_rate)) |>
  ggplot(aes(y = avg_homicide_rate, x = year, color = sex)) +
  geom_smooth(se = FALSE) +
  facet_grid(~region) + 
  labs(x = "Year",
       y = "Average Homicide Rate",
       Title = "Average Homicide Rate Trend")
```

## Data Transformation 

## Regression 

Split data into training and testing + visualize distributions 
```{r train/test + distribution}
train_df = sample_frac(merged_violence_df, size = 0.8)
test_df = anti_join(merged_violence_df, train_df, by = "gdp")

plot_distributions = function(column, name) {
  
  if(is.numeric(column) & name != "year") {
    ggplot(train_df, aes(x = column)) +
    geom_density() +
    labs(title = paste("Distribution of", name))
  }
  
}

train_list = colnames(train_df)
map(train_list, \(x) plot_distributions(pull(train_df, x), x))
```

After looking at the distributions of all variables, all variables are skewed 
right, except for human development index which is bimodal and slightly 
left-skewed. I will apply ln transformations and box-cox transformations to 
these variables, and use the Shapiro-Wilk test to test for normality. Even 
though it is not necessary to normalize the predictors, this step will stablize 
variance and reduce heteroscedasticity. I think it will be helpful for further 
steps with model.

Transformation step involves writing a function for ln transformation and a 
function for box_cox transformation. The functions will be mapped into the 
nested listcol which includes all continuous variables in the train_df dataset. 

```{r ln_transform}
ln_transform = function(value) {
  return(log(abs(value)))
}

ln_train_df = 
  train_df |>
  mutate(across(c(homicide_rate:alcohol_consumption), 
                ln_transform))

map(train_list, \(x) plot_distributions(pull(ln_train_df, x), x))
```

```{r boxcox_transform}
library(MASS)
boxcox_transform = function(value) {
  value = value + abs(min(value, na.rm = TRUE)) + 0.00001
  
  boxcox_result = boxcox(value ~ 1, plotit = FALSE)
  lambda = boxcox_result$x[which.max(boxcox_result$y)]
  if(lambda == 0) {
    return(log(value))
  }
  return((value^lambda - 1) / lambda)
}

boxcox_train_df = 
  train_df |>
  mutate(across(c(homicide_rate:alcohol_consumption), 
                boxcox_transform))

map(train_list, \(x) plot_distributions(pull(boxcox_train_df, x), x))
```



